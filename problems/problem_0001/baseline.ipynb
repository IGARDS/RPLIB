{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RPLib Problem 0001\n",
    "## Baseline\n",
    "\n",
    "Goal of this notebook is to analyze and visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import skew\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter-pander14'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "home = str(Path.home())\n",
    "home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"%s/rankability_toolbox_dev\"%home)\n",
    "import pyrankability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,\"%s/sensitivity_study/src\"%home)\n",
    "from sensitivity_tests import *\n",
    "from utilities import *\n",
    "from base import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = joblib.load(\"/disk/RPLib/problem_0001.joblib.z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A practitioner wants to predict the degree to which a the rankings during season \n",
      "of the NCAA Men’s Basketball are likely to change as more games are played (i.e., sensitivity to more games). \n",
      "They want to start the analysis after a minimum of 50% of the games are played. \n",
      "They want to run Massey and Colley.\n",
      "\n",
      "Sensitivity of new games will be measured as the intersection of between two \n",
      "rankings derived from before and after the new games are included.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(problem[\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frac1</th>\n",
       "      <th>frac2</th>\n",
       "      <th>domain</th>\n",
       "      <th>range</th>\n",
       "      <th>direct_thres</th>\n",
       "      <th>spread_thres</th>\n",
       "      <th>weight_indirect</th>\n",
       "      <th>Method</th>\n",
       "      <th>Year</th>\n",
       "      <th>top10_intersection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>all</td>\n",
       "      <td>madness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Massey</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>all</td>\n",
       "      <td>madness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Colley</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>all</td>\n",
       "      <td>madness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Massey</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>all</td>\n",
       "      <td>madness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Colley</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>all</td>\n",
       "      <td>madness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Massey</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>madness</td>\n",
       "      <td>madness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Colley</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>madness</td>\n",
       "      <td>madness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Massey</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>madness</td>\n",
       "      <td>madness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Colley</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>madness</td>\n",
       "      <td>madness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Massey</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>madness</td>\n",
       "      <td>madness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Colley</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1020 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      frac1  frac2   domain    range  direct_thres  spread_thres  \\\n",
       "0       0.5    0.6      all  madness           1.0           3.0   \n",
       "1       0.5    0.6      all  madness           1.0           3.0   \n",
       "2       0.5    0.7      all  madness           1.0           3.0   \n",
       "3       0.5    0.7      all  madness           1.0           3.0   \n",
       "4       0.5    0.8      all  madness           1.0           3.0   \n",
       "...     ...    ...      ...      ...           ...           ...   \n",
       "1015    0.8    0.9  madness  madness           1.0           3.0   \n",
       "1016    0.8    1.0  madness  madness           1.0           3.0   \n",
       "1017    0.8    1.0  madness  madness           1.0           3.0   \n",
       "1018    0.9    1.0  madness  madness           1.0           3.0   \n",
       "1019    0.9    1.0  madness  madness           1.0           3.0   \n",
       "\n",
       "      weight_indirect  Method  Year  top10_intersection  \n",
       "0                0.25  Massey  2002                 0.2  \n",
       "1                0.25  Colley  2002                 0.4  \n",
       "2                0.25  Massey  2002                 0.1  \n",
       "3                0.25  Colley  2002                 0.3  \n",
       "4                0.25  Massey  2002                 0.1  \n",
       "...               ...     ...   ...                 ...  \n",
       "1015             0.25  Colley  2018                 0.1  \n",
       "1016             0.25  Massey  2018                 0.4  \n",
       "1017             0.25  Colley  2018                 0.2  \n",
       "1018             0.25  Massey  2018                 0.2  \n",
       "1019             0.25  Colley  2018                 0.2  \n",
       "\n",
       "[1020 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem['data'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['frac=0.5', 'frac=0.6', 'frac=0.7', 'frac=0.8', 'frac=0.9', 'frac=1.0'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem['data']['2002'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(problem['data'].keys())\n",
    "frac_keys = list(problem['data'][years[0]].keys())\n",
    "remaining_games = problem['other']['remaining_games']\n",
    "madness_teams = problem['other']['madness_teams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to search\n",
    "direct_thress = [0]\n",
    "spread_thress = [0]\n",
    "weight_indirects = [0.25]\n",
    "domains_ranges = [('all','madness')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_D(game_df,team_range,direct_thres,spread_thres,weight_indirect):\n",
    "    map_func = lambda linked: pyrankability.construct.support_map_vectorized_direct_indirect_weighted(linked,direct_thres=direct_thres,spread_thres=spread_thres,weight_indirect=weight_indirect)\n",
    "    D = pyrankability.construct.V_count_vectorized(game_df,map_func).reindex(index=team_range,columns=team_range)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\"delta_lop\",\"delta_hillside\",\"nfrac_xstar_lop\",\"nfrac_xstar_hillside\",\"diameter_lop\",\"diameter_hillside\"]\n",
    "\n",
    "def calc_tau(n,obj):\n",
    "    nchoose2 = pyrankability.common.nCr(n,2)\n",
    "    tau = (nchoose2 - obj)/nchoose2\n",
    "    return tau\n",
    "\n",
    "def compute_features(D):\n",
    "    delta_lop,details_lop = pyrankability.rank.solve(D.fillna(0),method='lop',cont=True)\n",
    "\n",
    "    x = pd.DataFrame(details_lop['x'],index=D.index,columns=D.columns)\n",
    "    r = x.sum(axis=0)\n",
    "    order = np.argsort(r)\n",
    "    xstar = x.iloc[order,:].iloc[:,order]\n",
    "    xstar.loc[:,:] = pyrankability.common.threshold_x(xstar.values)\n",
    "    inxs = np.triu_indices(len(xstar),k=1)\n",
    "    xstar_upper = xstar.values[inxs[0],inxs[1]]\n",
    "    nfrac_upper_lop = sum((xstar_upper > 0) & (xstar_upper < 1))\n",
    "    \n",
    "    k_two_distant,details_two_distant = pyrankability.search.solve_pair_max_tau(D.fillna(0),method='lop',verbose=False)\n",
    "    d_lop = calc_tau(len(D),details_two_distant['obj'])\n",
    "    \n",
    "    delta_hillside,details_hillside = pyrankability.rank.solve(D,method='hillside',cont=True)\n",
    "    \n",
    "    x = pd.DataFrame(details_hillside['x'],index=D.index,columns=D.columns)\n",
    "    r = x.sum(axis=0)\n",
    "    order = np.argsort(r)\n",
    "    xstar = x.iloc[order,:].iloc[:,order]\n",
    "    xstar.loc[:,:] = pyrankability.common.threshold_x(xstar.values)\n",
    "    inxs = np.triu_indices(len(xstar),k=1)\n",
    "    xstar_upper = xstar.values[inxs[0],inxs[1]]\n",
    "    nfrac_upper_hillside = sum((xstar_upper > 0) & (xstar_upper < 1))\n",
    "    \n",
    "    k_two_distant,details_two_distant = pyrankability.search.solve_pair_max_tau(D,method='hillside',verbose=False)\n",
    "    d_hillside = calc_tau(len(D),details_two_distant['obj'])\n",
    "    \n",
    "    features = pd.Series([delta_lop,delta_hillside,2*nfrac_upper_lop,2*nfrac_upper_hillside,d_lop,d_hillside],index=feature_columns)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"top10_intersection\"\n",
    "def process(data,target):\n",
    "    index_cols = [\"Year\",\"frac_key\",\"direct_thres\",\"spread_thres\",\"weight_indirect\",\"range\"]\n",
    "    Ds = pd.DataFrame(columns=[\"D\"]+index_cols)\n",
    "    Ds.set_index(index_cols,inplace=True)\n",
    "    outer_keys = list(itertools.product(years,frac_keys,direct_thress,spread_thress,weight_indirects,domains_ranges))\n",
    "    for year,frac_key,dt,st,iw,domain_range in tqdm(outer_keys):\n",
    "       # set the team_range\n",
    "        team_range = None\n",
    "        ran = domain_range[1]\n",
    "        if ran == 'madness':\n",
    "            team_range = madness_teams[year]\n",
    "        elif ran == 'all':\n",
    "            team_range = all_teams[year]\n",
    "        elif \"top\" in ran:\n",
    "            team_range = all_teams[year]\n",
    "        D = compute_D(data[year][frac_key],team_range,dt,st,iw)\n",
    "        Ds = Ds.append(pd.Series([D],index=[\"D\"],name=(year,frac_key,dt,st,iw,ran))) \n",
    "    return Ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 3/102 [00:00<00:04, 22.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 6/102 [00:00<00:04, 21.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|▉         | 9/102 [00:00<00:04, 22.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 12/102 [00:00<00:04, 21.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█▍        | 15/102 [00:00<00:03, 22.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|█▊        | 18/102 [00:00<00:03, 21.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|██        | 21/102 [00:00<00:03, 22.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|██▎       | 24/102 [00:01<00:03, 21.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▋       | 27/102 [00:01<00:03, 22.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|██▉       | 30/102 [00:01<00:03, 21.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|███▏      | 33/102 [00:01<00:03, 22.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|███▌      | 36/102 [00:01<00:03, 21.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 39/102 [00:01<00:02, 21.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|████      | 42/102 [00:01<00:02, 21.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 21.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 21.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 51/102 [00:02<00:02, 21.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|█████▎    | 54/102 [00:02<00:02, 17.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████▌    | 57/102 [00:02<00:02, 19.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|█████▉    | 60/102 [00:02<00:02, 19.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████▏   | 63/102 [00:03<00:01, 19.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▍   | 66/102 [00:03<00:01, 19.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|██████▊   | 69/102 [00:03<00:01, 20.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████   | 72/102 [00:03<00:01, 19.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▎  | 75/102 [00:03<00:01, 20.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|███████▋  | 78/102 [00:03<00:01, 20.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|███████▉  | 81/102 [00:03<00:01, 20.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|████████▏ | 84/102 [00:04<00:00, 19.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████▌ | 87/102 [00:04<00:00, 20.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|████████▊ | 90/102 [00:04<00:00, 20.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|█████████ | 93/102 [00:04<00:00, 20.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|█████████▍| 96/102 [00:04<00:00, 20.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████▋| 99/102 [00:04<00:00, 20.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 102/102 [00:04<00:00, 19.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "Ds = process(problem['data'],problem['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>team2</th>\n",
       "      <th>Alabama</th>\n",
       "      <th>Alcorn_St</th>\n",
       "      <th>Arizona</th>\n",
       "      <th>Boston_College</th>\n",
       "      <th>Boston_Univ</th>\n",
       "      <th>California</th>\n",
       "      <th>Central_Conn</th>\n",
       "      <th>Charlotte</th>\n",
       "      <th>Cincinnati</th>\n",
       "      <th>Connecticut</th>\n",
       "      <th>...</th>\n",
       "      <th>UNC_Wilmington</th>\n",
       "      <th>USC</th>\n",
       "      <th>Utah</th>\n",
       "      <th>Valparaiso</th>\n",
       "      <th>W_Kentucky</th>\n",
       "      <th>Wake_Forest</th>\n",
       "      <th>Winthrop</th>\n",
       "      <th>Wisconsin</th>\n",
       "      <th>Wyoming</th>\n",
       "      <th>Xavier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcorn_St</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boston_College</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boston_Univ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wake_Forest</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winthrop</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xavier</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "team2           Alabama  Alcorn_St  Arizona  Boston_College  Boston_Univ  \\\n",
       "team1                                                                      \n",
       "Alabama             NaN        NaN      NaN             NaN          NaN   \n",
       "Alcorn_St           NaN        NaN      NaN             NaN          NaN   \n",
       "Arizona             NaN        NaN      NaN             NaN          NaN   \n",
       "Boston_College      NaN        NaN      NaN             NaN          NaN   \n",
       "Boston_Univ         NaN        NaN      NaN             NaN          NaN   \n",
       "...                 ...        ...      ...             ...          ...   \n",
       "Wake_Forest         NaN        NaN      NaN             NaN          NaN   \n",
       "Winthrop            NaN        NaN      NaN             NaN          NaN   \n",
       "Wisconsin           NaN        NaN      NaN             NaN          NaN   \n",
       "Wyoming             NaN        NaN      NaN             NaN          NaN   \n",
       "Xavier              0.0        NaN      0.0             NaN          NaN   \n",
       "\n",
       "team2           California  Central_Conn  Charlotte  Cincinnati  Connecticut  \\\n",
       "team1                                                                          \n",
       "Alabama                NaN           NaN        NaN         NaN          NaN   \n",
       "Alcorn_St              NaN           NaN        NaN         NaN          NaN   \n",
       "Arizona                NaN           NaN        NaN         0.0          NaN   \n",
       "Boston_College         NaN           NaN        NaN         NaN          NaN   \n",
       "Boston_Univ            NaN           NaN        NaN         NaN          NaN   \n",
       "...                    ...           ...        ...         ...          ...   \n",
       "Wake_Forest            NaN           NaN        NaN         NaN          NaN   \n",
       "Winthrop               NaN           NaN        NaN         NaN          NaN   \n",
       "Wisconsin              NaN           NaN        NaN         NaN          NaN   \n",
       "Wyoming                NaN           NaN        NaN         NaN          NaN   \n",
       "Xavier                 NaN           NaN        NaN         0.0          NaN   \n",
       "\n",
       "team2           ...  UNC_Wilmington  USC  Utah  Valparaiso  W_Kentucky  \\\n",
       "team1           ...                                                      \n",
       "Alabama         ...             NaN  NaN   NaN         NaN         NaN   \n",
       "Alcorn_St       ...             NaN  NaN   NaN         NaN         NaN   \n",
       "Arizona         ...             NaN  NaN   NaN         NaN         NaN   \n",
       "Boston_College  ...             NaN  NaN   NaN         NaN         NaN   \n",
       "Boston_Univ     ...             NaN  NaN   NaN         NaN         NaN   \n",
       "...             ...             ...  ...   ...         ...         ...   \n",
       "Wake_Forest     ...             NaN  NaN   NaN         NaN         NaN   \n",
       "Winthrop        ...             NaN  NaN   NaN         NaN         NaN   \n",
       "Wisconsin       ...             NaN  NaN   NaN         NaN         NaN   \n",
       "Wyoming         ...             NaN  NaN   NaN         NaN         NaN   \n",
       "Xavier          ...             NaN  NaN   NaN         NaN         NaN   \n",
       "\n",
       "team2           Wake_Forest  Winthrop  Wisconsin  Wyoming  Xavier  \n",
       "team1                                                              \n",
       "Alabama                 NaN       NaN        NaN      NaN    0.00  \n",
       "Alcorn_St               NaN       NaN        NaN      NaN     NaN  \n",
       "Arizona                 NaN       NaN        NaN      NaN    0.25  \n",
       "Boston_College          NaN       NaN        NaN      NaN     NaN  \n",
       "Boston_Univ             NaN       NaN        NaN      NaN     NaN  \n",
       "...                     ...       ...        ...      ...     ...  \n",
       "Wake_Forest             NaN       NaN        NaN      NaN     NaN  \n",
       "Winthrop                NaN       NaN        NaN      NaN     NaN  \n",
       "Wisconsin               NaN       NaN        NaN      NaN     NaN  \n",
       "Wyoming                 NaN       NaN        NaN      NaN     NaN  \n",
       "Xavier                  NaN       NaN        NaN      NaN     NaN  \n",
       "\n",
       "[65 rows x 65 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ds.loc[('2002','frac=0.5',0,0,0.25,'madness'),'D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenList(['Year', 'frac_key', 'direct_thres', 'spread_thres', 'weight_indirect', 'range'])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ds.index.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(Ds):\n",
    "    index_cols = list(Ds.index.names)\n",
    "    X = pd.DataFrame(columns=index_cols + feature_columns)\n",
    "    X.set_index(index_cols,inplace=True)\n",
    "    for index,row in tqdm(Ds.iterrows()):\n",
    "        year,frac_key,dt,st,iw,ran = index\n",
    "        features = compute_features(Ds.loc[(year,frac_key,dt,st,iw,ran),\"D\"])\n",
    "        features.name = index\n",
    "        X = X.append(features)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1it [00:34, 34.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2it [01:12, 35.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3it [01:54, 37.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4it [02:35, 38.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5it [03:06, 36.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6it [03:41, 35.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "X = create_features(Ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = list(Ds.index.names)\n",
    "index_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refine the target dataset\n",
    "We will try to predict the average over the parameters run for each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = problem['target'].groupby(['frac1','frac2','Method','Year'])['top10_intersection'].mean().to_frame()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_for_join = X.copy().reset_index()\n",
    "X_for_join['frac1']= X_for_join['frac_key'].str.replace(\"frac=\",\"\").astype(float)\n",
    "X_for_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = target.reset_index().set_index(['frac1','Year']).join(X_for_join.set_index(['frac1','Year']))\n",
    "Xy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narrowing our goal to 0.5 and 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Xy.reset_index().set_index(['frac1','frac2']).loc[0.5,0.6]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "features = [\"delta_lop\",\"delta_hillside\"]\n",
    "for_index = list(data.drop(features+['Year']+[target_column],axis=1).columns)\n",
    "scaled_data = data.copy().reset_index().set_index(for_index)\n",
    "for ix in scaled_data.index.unique():\n",
    "    print(\"Scaling for group of\",ix)\n",
    "    scaled_data.loc[ix,features] = scale(scaled_data.loc[ix,features])\n",
    "scaled_data = scaled_data.reset_index()\n",
    "scaled_data[target_column] = data[target_column].values\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# based on 5x2 from http://ieeexplore.ieee.org/document/6790639/\n",
    "# Dietterich also recommends a resampling method of his own devising called 5×2 cross-validation that involves 5 repeats of 2-fold cross-validation.\n",
    "# Two folds are chosen to ensure that each observation appears only in the train or \n",
    "# test dataset for a single estimate of model skill. A paired Student’s t-test is used \n",
    "# on the results, updated to better reflect the limited degrees of freedom given the \n",
    "# dependence between the estimated skill scores.\n",
    "# This interval is 2.571 for a 5% threshold and 3.365 for a 2% thresholds (https://www.medcalc.org/manual/t-distribution.php)\n",
    "\n",
    "def evaluate(df,pred_col,model1,model2,param_grid1={},param_grid2={},feature_cols=[\"delta_lop\",\"delta_hillside\"]):\n",
    "    trn = df[feature_cols]\n",
    "    target = df[pred_col]\n",
    "    # Choose seeds for each 2-fold iterations\n",
    "    seeds = [13, 51, 137, 24659, 347]\n",
    "    # Initialize the score difference for the 1st fold of the 1st iteration \n",
    "    p_1_1 = 0.0\n",
    "    # Initialize a place holder for the variance estimate\n",
    "    s_sqr = 0.0\n",
    "    # Initialize scores list for both classifiers\n",
    "    scores_1 = []\n",
    "    scores_2 = []\n",
    "    diff_scores = []\n",
    "    # Iterate through 5 2-fold CV\n",
    "    for i_s, seed in enumerate(seeds):\n",
    "        # Split the dataset in 2 parts with the current seed\n",
    "        folds = KFold(n_splits=2, shuffle=True, random_state=seed)\n",
    "        # Initialize score differences\n",
    "        p_i = np.zeros(2)\n",
    "        # Go through the current 2 fold\n",
    "        for i_f, (trn_idx, val_idx) in enumerate(folds.split(target, target)):\n",
    "            # Split the data\n",
    "            trn_x, trn_y = trn.iloc[trn_idx], target.iloc[trn_idx]\n",
    "            val_x, val_y = trn.iloc[val_idx], target.iloc[val_idx]\n",
    "            cv = [(slice(None), slice(None))] # don't perform any cross validation\n",
    "            grid1 = GridSearchCV(model1,param_grid1,verbose=0,n_jobs=-1,cv=cv,refit=True)\n",
    "            grid2 = GridSearchCV(model2,param_grid2,verbose=0,n_jobs=-1,cv=cv,refit=True)\n",
    "            # Train classifiers\n",
    "            grid1.fit(trn_x, trn_y)\n",
    "            grid2.fit(trn_x, trn_y)\n",
    "            best_estimator1 = grid1.best_estimator_\n",
    "            best_estimator2 = grid2.best_estimator_\n",
    "            errors1 = val_y - best_estimator1.predict(val_x).flat\n",
    "            errors2 = val_y - best_estimator2.predict(val_x).flat\n",
    "            score_1 = -np.mean(np.abs(errors1))\n",
    "            score_2 = -np.mean(np.abs(errors2))\n",
    "\n",
    "            # keep score history for mean and stdev calculation\n",
    "            scores_1.append(score_1)\n",
    "            scores_2.append(score_2)\n",
    "            diff_scores.append(score_1 - score_2)\n",
    "            #print(\"Fold %2d score difference = %.6f\" % (i_f + 1, score_1 - score_2))\n",
    "            # Compute score difference for current fold  \n",
    "            p_i[i_f] = score_1 - score_2\n",
    "            # Keep the score difference of the 1st iteration and 1st fold\n",
    "            if (i_s == 0) & (i_f == 0):\n",
    "                p_1_1 = p_i[i_f]\n",
    "        # Compute mean of scores difference for the current 2-fold CV\n",
    "        p_i_bar = (p_i[0] + p_i[1]) / 2\n",
    "        # Compute the variance estimate for the current 2-fold CV\n",
    "        s_i_sqr = (p_i[0] - p_i_bar) ** 2 + (p_i[1] - p_i_bar) ** 2 \n",
    "        # Add up to the overall variance\n",
    "        s_sqr += s_i_sqr\n",
    "\n",
    "    # Compute t value as the first difference divided by the square root of variance estimate\n",
    "    t_bar = p_1_1 / ((s_sqr / 5) ** .5) \n",
    " \n",
    "    return pd.Series([t_bar,np.mean(diff_scores), np.std(diff_scores),np.mean(scores_1),np.mean(scores_2),np.std(scores_1),np.std(scores_2)],index=[\"t_bar\",\"Difference Mean\",\"Difference Stdev\",\"Mean Score 1\",\"Mean Score 2\",\"Stdev 1\",\"Stdev 2\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Method',\n",
       " 'frac_key',\n",
       " 'direct_thres',\n",
       " 'spread_thres',\n",
       " 'weight_indirect',\n",
       " 'range']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_svr_results = scaled_data.groupby(for_index).apply(evaluate,target_column,DummyRegressor(),SVR(gamma='scale'),param_grid1 = {},\n",
    "                                                                           param_grid2 = {'C': [0.1,1,10], \n",
    "                                                                                   'epsilon': [0.1,0.5,1.],\n",
    "                                                                                   'kernel': ['linear']#, 'poly', 'rbf', 'sigmoid'],\n",
    "                                                                                  })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>t_bar</th>\n",
       "      <th>Difference Mean</th>\n",
       "      <th>Difference Stdev</th>\n",
       "      <th>Mean Score 1</th>\n",
       "      <th>Mean Score 2</th>\n",
       "      <th>Stdev 1</th>\n",
       "      <th>Stdev 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th>frac_key</th>\n",
       "      <th>direct_thres</th>\n",
       "      <th>spread_thres</th>\n",
       "      <th>weight_indirect</th>\n",
       "      <th>range</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Colley</th>\n",
       "      <th>frac=0.5</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0.25</th>\n",
       "      <th>madness</th>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.006281</td>\n",
       "      <td>0.030096</td>\n",
       "      <td>-0.069306</td>\n",
       "      <td>-0.075587</td>\n",
       "      <td>0.015835</td>\n",
       "      <td>0.029062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Massey</th>\n",
       "      <th>frac=0.5</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0.25</th>\n",
       "      <th>madness</th>\n",
       "      <td>0.318519</td>\n",
       "      <td>0.010834</td>\n",
       "      <td>0.015323</td>\n",
       "      <td>-0.072222</td>\n",
       "      <td>-0.083056</td>\n",
       "      <td>0.011275</td>\n",
       "      <td>0.021677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      t_bar  \\\n",
       "Method frac_key direct_thres spread_thres weight_indirect range               \n",
       "Colley frac=0.5 0            0            0.25            madness  0.001696   \n",
       "Massey frac=0.5 0            0            0.25            madness  0.318519   \n",
       "\n",
       "                                                                   Difference Mean  \\\n",
       "Method frac_key direct_thres spread_thres weight_indirect range                      \n",
       "Colley frac=0.5 0            0            0.25            madness         0.006281   \n",
       "Massey frac=0.5 0            0            0.25            madness         0.010834   \n",
       "\n",
       "                                                                   Difference Stdev  \\\n",
       "Method frac_key direct_thres spread_thres weight_indirect range                       \n",
       "Colley frac=0.5 0            0            0.25            madness          0.030096   \n",
       "Massey frac=0.5 0            0            0.25            madness          0.015323   \n",
       "\n",
       "                                                                   Mean Score 1  \\\n",
       "Method frac_key direct_thres spread_thres weight_indirect range                   \n",
       "Colley frac=0.5 0            0            0.25            madness     -0.069306   \n",
       "Massey frac=0.5 0            0            0.25            madness     -0.072222   \n",
       "\n",
       "                                                                   Mean Score 2  \\\n",
       "Method frac_key direct_thres spread_thres weight_indirect range                   \n",
       "Colley frac=0.5 0            0            0.25            madness     -0.075587   \n",
       "Massey frac=0.5 0            0            0.25            madness     -0.083056   \n",
       "\n",
       "                                                                    Stdev 1  \\\n",
       "Method frac_key direct_thres spread_thres weight_indirect range               \n",
       "Colley frac=0.5 0            0            0.25            madness  0.015835   \n",
       "Massey frac=0.5 0            0            0.25            madness  0.011275   \n",
       "\n",
       "                                                                    Stdev 2  \n",
       "Method frac_key direct_thres spread_thres weight_indirect range              \n",
       "Colley frac=0.5 0            0            0.25            madness  0.029062  \n",
       "Massey frac=0.5 0            0            0.25            madness  0.021677  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_svr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "dummy_linear_results = scaled_data.groupby(for_index).apply(evaluate,target_column,DummyRegressor(),\n",
    "                                                            LinearRegression(),param_grid1 = {},\n",
    "                                                            param_grid2 = {})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>t_bar</th>\n",
       "      <th>Difference Mean</th>\n",
       "      <th>Difference Stdev</th>\n",
       "      <th>Mean Score 1</th>\n",
       "      <th>Mean Score 2</th>\n",
       "      <th>Stdev 1</th>\n",
       "      <th>Stdev 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th>frac_key</th>\n",
       "      <th>direct_thres</th>\n",
       "      <th>spread_thres</th>\n",
       "      <th>weight_indirect</th>\n",
       "      <th>range</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Colley</th>\n",
       "      <th>frac=0.5</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0.25</th>\n",
       "      <th>madness</th>\n",
       "      <td>-0.044668</td>\n",
       "      <td>0.028209</td>\n",
       "      <td>0.067776</td>\n",
       "      <td>-0.069306</td>\n",
       "      <td>-0.097515</td>\n",
       "      <td>0.015835</td>\n",
       "      <td>0.064442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Massey</th>\n",
       "      <th>frac=0.5</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0.25</th>\n",
       "      <th>madness</th>\n",
       "      <td>0.291950</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>0.069604</td>\n",
       "      <td>-0.072222</td>\n",
       "      <td>-0.131279</td>\n",
       "      <td>0.011275</td>\n",
       "      <td>0.078396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      t_bar  \\\n",
       "Method frac_key direct_thres spread_thres weight_indirect range               \n",
       "Colley frac=0.5 0            0            0.25            madness -0.044668   \n",
       "Massey frac=0.5 0            0            0.25            madness  0.291950   \n",
       "\n",
       "                                                                   Difference Mean  \\\n",
       "Method frac_key direct_thres spread_thres weight_indirect range                      \n",
       "Colley frac=0.5 0            0            0.25            madness         0.028209   \n",
       "Massey frac=0.5 0            0            0.25            madness         0.059057   \n",
       "\n",
       "                                                                   Difference Stdev  \\\n",
       "Method frac_key direct_thres spread_thres weight_indirect range                       \n",
       "Colley frac=0.5 0            0            0.25            madness          0.067776   \n",
       "Massey frac=0.5 0            0            0.25            madness          0.069604   \n",
       "\n",
       "                                                                   Mean Score 1  \\\n",
       "Method frac_key direct_thres spread_thres weight_indirect range                   \n",
       "Colley frac=0.5 0            0            0.25            madness     -0.069306   \n",
       "Massey frac=0.5 0            0            0.25            madness     -0.072222   \n",
       "\n",
       "                                                                   Mean Score 2  \\\n",
       "Method frac_key direct_thres spread_thres weight_indirect range                   \n",
       "Colley frac=0.5 0            0            0.25            madness     -0.097515   \n",
       "Massey frac=0.5 0            0            0.25            madness     -0.131279   \n",
       "\n",
       "                                                                    Stdev 1  \\\n",
       "Method frac_key direct_thres spread_thres weight_indirect range               \n",
       "Colley frac=0.5 0            0            0.25            madness  0.015835   \n",
       "Massey frac=0.5 0            0            0.25            madness  0.011275   \n",
       "\n",
       "                                                                    Stdev 2  \n",
       "Method frac_key direct_thres spread_thres weight_indirect range              \n",
       "Colley frac=0.5 0            0            0.25            madness  0.064442  \n",
       "Massey frac=0.5 0            0            0.25            madness  0.078396  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_linear_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top10_intersection</th>\n",
       "      <th>delta_lop</th>\n",
       "      <th>delta_hillside</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>top10_intersection</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.282327</td>\n",
       "      <td>0.332860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_lop</th>\n",
       "      <td>0.282327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_hillside</th>\n",
       "      <td>0.332860</td>\n",
       "      <td>0.971624</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    top10_intersection  delta_lop  delta_hillside\n",
       "top10_intersection            1.000000   0.282327        0.332860\n",
       "delta_lop                     0.282327   1.000000        0.971624\n",
       "delta_hillside                0.332860   0.971624        1.000000"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.set_index('Method').loc['Colley'][[\"top10_intersection\",\"delta_lop\",\"delta_hillside\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
